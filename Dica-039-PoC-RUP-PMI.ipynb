{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e954fbcb-7915-44e7-8bee-68447be1775f",
   "metadata": {},
   "source": [
    "<img width=\"200\" style=\"float:right\" src=\"https://github.com/danielscarvalho/Insper-DS-Dicas/blob/master/Insper-Logo.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549c7f1-01bb-4315-877b-66d9f99e2502",
   "metadata": {},
   "source": [
    "# Computação para Ciências dos Dados\n",
    "\n",
    "<sub><a href=\"https://www.insper.edu.br/pt/cursos/pos-graduacao/programas-avancados/programas-avancados-data-science-e-decisao\">PÓS-\n",
    "GRADUAÇÃO EM DATA SCIENCE E DECISÃO</a></sub>\n",
    "\n",
    "## Dica do Dia: 039\n",
    "\n",
    "[This hint is in English]\n",
    "\n",
    "Undergrad and post-graduation computer science and engineering students has lots of opportunities to make short projects of WEB sites, WEB APIs, mobile apps, and data science.\n",
    "\n",
    "Students usually inquire about how long it takes and how to give a price for it.\n",
    "\n",
    "In engineering and business, we have lots of tools and data about it, here I am compiling some thoughts with LLM AI from X Grook and OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d7279-1410-497b-af95-fc4de1f1ee71",
   "metadata": {},
   "source": [
    "Those are traditional enterprise frameworks that have been used in big companies and big projects; they really work, making ideas in real-world applications:\n",
    "\n",
    "- PMI (Project Management Institute) has a very well-known good practice, PMBOK, about how to manage projects for both engineering and business\n",
    "- RUP (Rational Unified Process or Unified Process), this is about software engineering good practices and in some sense is close to PMI ideas, but focuses on software development, requirement gathering, and documentation with UML, BPMN, and other graphical management tools.\n",
    "\n",
    "> I will talk about agile and Design Sprint in the next article\n",
    "\n",
    "Pricing enterprise services is usually related to team working hours (hr - human resources). To define working hours needed, we use those frameworks for project management and software engineering. \n",
    "\n",
    "In many cases, the initial project briefing is vague. In the first phase of work, we refine the project scope (ASK, Inception) and then project a good vision of the project objectives. With support from those frameworks, we can define timing and pricing without digging into the process. All software and engineering projects have risks and uncertainty, and this is manageable.\n",
    "\n",
    "Both frameworks, RUP and PMI, break down the project into four main phases:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aff320-b91e-45df-a73a-46ef99f0cce8",
   "metadata": {},
   "source": [
    "PMI:\n",
    "<div style=\"width:600px;\">\n",
    "\n",
    "![PMI](img/image8-1-pmi.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "https://pressbooks.atlanticoer-relatlantique.ca/projectmanagement2024/chapter/chapter-2-adopting-the-project-management-framework/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a1efb-1376-4ab2-a38e-e4c2aa41bc0a",
   "metadata": {},
   "source": [
    "RUP:\n",
    "\n",
    "<div style=\"width:600px\">\n",
    "\n",
    "![RUP](img/rup-phases.gif)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83135acf-3bab-4509-8ed8-e506ebf59888",
   "metadata": {},
   "source": [
    "Another reference is the five phases of a data science project:\n",
    "\n",
    "1. ASK - 5%\n",
    "2. GET - 20%\n",
    "3. EXPLORE - 50%\n",
    "4. MODEL (AI ML) - 20%\n",
    "5. COMMUNICATE - 5%\n",
    "\n",
    "<div style=\"width:600px\">\n",
    "\n",
    "![](img/Data-Science-An-Overview-and-Its-Applications.webp)\n",
    "\n",
    "</div>\n",
    "\n",
    "https://www.tutorsindia.com/blog/data-science-an-overview-and-its-applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db8140-ab6b-4d3f-8ca2-b1e69e812c30",
   "metadata": {},
   "source": [
    "We can combine those frameworks by project and customer busiess practices to define timing and hr cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9200f-7fdb-4324-926a-917e8b370173",
   "metadata": {},
   "source": [
    "Hints:\n",
    "\n",
    "- For your first data science project, I suggest working with another friend (Pairing), avoiding working alone.\n",
    "- Try to define a PoC (Proof of Concept) with the customer, instead of a full project, and so, solve and focus on just one issue.\n",
    "- Try to set a 3 to 4-month project, 16 weeks.\n",
    "- Split this project time into four phases, as PMI and RUP suggest.\n",
    "- Price it in total amount of hours with two junior data scientists\n",
    "- USD 30.00 by hour × 2 jr engineers × 40 hours week × 16 weeks = USD 38,400.00\n",
    "   - Send a USD 43k quote and let 10% discount to procurement\n",
    "- Working on your first 3 projects, we're gonna get really confident\n",
    "- Usually, we do lots of upselling: new projects with the same customer\n",
    "- If there are big data science projects > 1 year, split it in multiple projects. 4-month data science projects are more successful than big projects\n",
    "- For the MODELING phase, try to use many AI ML models instead of focus and fine-tuning just one\n",
    "- EXPLORE clean and combine data from internal SQL systems, external, Internet, etc., will take from 50% to 60% of project time\n",
    "- MODEL, which is the more noble part of the project (AI ML), takes round 20% of the project time with good data\n",
    "- COMMUNICATE: create an executive report to share findings in just 3 slides (Title, subtitle, and graphics), and deploy the AI ML model as a WEB API (Docker + Flask)\n",
    "\n",
    "\n",
    "This is a 4-week PoC data science project by USD 43k\n",
    "\n",
    "> Be confident, you are Insper!! You learned and know what to do in business and tech. You need experience now, share this risk, and be honest with the customer. This PoC is closer to our capstone project, a bit more intense\n",
    "\n",
    "This \"PoC framework\" applies to app and web development projects too.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93771696-2769-48e1-8fba-91e9334da0a3",
   "metadata": {},
   "source": [
    "## Some additional thoughts aided by LLM AI Grok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d2270-bf20-43f4-a502-b8e27198de57",
   "metadata": {},
   "source": [
    "A Data Science Proof of Concept (PoC) is a small-scale, time-boxed experiment or prototype that demonstrates the technical feasibility, potential value, and viability of a specific data-driven idea, model, or use case—such as predictive analytics, machine learning classification, or demand forecasting—using real (or representative) enterprise data. The primary goal is to validate whether the concept can deliver meaningful results (e.g., sufficient accuracy, actionable insights, or ROI potential) with acceptable effort and risk, before investing in full-scale development, production deployment, or broader rollout. It typically focuses on one narrow problem, produces tangible evidence (like model performance metrics or a working demo), and helps build stakeholder confidence while identifying early challenges in data quality, integration, or scalability. [AI LLM Grok]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84322cd-b539-494f-952e-147a76cb6032",
   "metadata": {},
   "source": [
    "In **enterprise computing** (such as large-scale software solutions, cloud migrations, AI/ML implementations, ERP integrations, cybersecurity tools, data platforms, or infrastructure changes), a **Proof of Concept (PoC)** is a limited-scope test to validate technical feasibility, value, integration potential, and risk before committing to full deployment.\n",
    "\n",
    "Costs and timelines vary **significantly** depending on:\n",
    "\n",
    "- Scope and complexity (simple API test vs. multi-system integration with real enterprise data)\n",
    "- Technology involved (e.g., standard SaaS vs. custom AI, blockchain, or heavy data processing)\n",
    "- Team (vendor, internal, or outsourced; location affects rates)\n",
    "- Whether it's vendor-led (often partly \"free\" or low-cost to win business) or fully custom-built\n",
    "- Success criteria and success metrics defined upfront\n",
    "\n",
    "### Typical Cost Ranges (2025–2026 data)\n",
    "These are rough ballpark figures in **USD** for enterprise-grade PoCs (often higher than startup/simple app PoCs):\n",
    "\n",
    "- **Simple / narrow PoC** (basic feasibility, single feature/use case, minimal integrations): **$10,000 – $40,000**\n",
    "- **Medium complexity** (2–4 key features, some integrations/APIs, dashboards, real-ish data testing): **$30,000 – $80,000–$100,000**\n",
    "- **Complex / enterprise-grade** (multi-system integration, compliance/security requirements, custom AI/ML, large datasets, regulated industry): **$80,000 – $200,000+** (can reach $300k+ in very heavy cases)\n",
    "\n",
    "Many vendor PoCs in enterprise sales cycles are structured as **paid pilots** at lower entry points (**$5,000–$50,000** fixed fee) to show seriousness, or even free/lightly discounted to close bigger deals later. Fully custom/internal PoCs tend toward the higher end.\n",
    "\n",
    "### Typical Duration\n",
    "Enterprise PoCs are deliberately **time-boxed** to maintain momentum:\n",
    "\n",
    "- **Very quick / focused** (single question, cloud setup, basic test): **2–4 weeks**\n",
    "- **Standard enterprise sales PoC** (real data, multiple use cases, stakeholder demos): **4–8 weeks** (most common range)\n",
    "- **Complex / thorough** (heavy integration, compliance testing, performance benchmarking): **8–16 weeks** (sometimes up to 3–4 months)\n",
    "\n",
    "Longer than ~90 days usually signals poor scoping and risks deal fatigue.\n",
    "\n",
    "### Quick Comparison Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb29ab-eb01-4984-b1d4-c9022de24bb7",
   "metadata": {},
   "source": [
    "\n",
    "| PoC Type              | Typical Cost (USD)     | Typical Duration     | Avg Cost per Week (approx.) | Common Examples in Enterprise                  |\n",
    "|-----------------------|------------------------|----------------------|-----------------------------|------------------------------------------------|\n",
    "| Simple feasibility    | $10k – $40k           | 2–6 weeks           | **$4,000 – $7,000**        | Cloud migration test, basic API connector     |\n",
    "| Medium / typical      | $30k – $100k          | 4–10 weeks          | **$6,000 – $12,000**       | AI use-case validation, ERP module integration|\n",
    "| Complex / high-stakes | $80k – $200k+         | 8–16+ weeks         | **$10,000 – $18,000+**     | Multi-cloud security PoC, large-scale GenAI with compliance |\n",
    "\n",
    "**Key advice** → Define very clear success criteria, limit scope ruthlessly, and time-box aggressively (e.g., \"4 weeks max\") to control both cost and timeline. Many enterprises now prefer short, paid, outcome-focused PoCs over long free trials.\n",
    "\n",
    "If you share more details (e.g., the specific technology/area like AI, cloud, cybersecurity, or ERP), I can give a more precise estimate!\n",
    "    \n",
    "### Quick Notes on the \"Avg Cost per Week\" Column\n",
    "- These are **mid-range estimates** (e.g., for simple: ~$25k midpoint ÷ ~4 weeks midpoint ≈ $6,250 → rounded into the shown range).\n",
    "- Real weekly costs are **not perfectly linear** — most spending happens in weeks 2–5 (design, build, integration, testing), while week 1 (scoping/setup) and final week (demo/wrap-up) are usually lighter.\n",
    "- In vendor-led PoCs, the \"effective\" weekly cost to the buyer can be **much lower** (or near zero) if it's a discounted/paid pilot structured to land the bigger contract.\n",
    "- Internal/custom PoCs (your own team or hired consultants) usually hit the higher end of these weekly figures due to full labor rates.\n",
    "\n",
    "If you'd like me to adjust the calculation logic (e.g., use lower/higher ends instead of midpoints, factor in team size, or add regional adjustments for Brazil/LATAM rates), just let me know! Or if you have a specific PoC scenario in mind, I can refine the numbers further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd3c29-eef7-4569-b76f-32771b096574",
   "metadata": {},
   "source": [
    "## PMI, RUP and Data Science Process\n",
    "\n",
    "How to manage project time:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b3ea1-19a1-45f0-9f3a-e4cf75da4383",
   "metadata": {},
   "source": [
    "To relate the **four phases of software engineering projects** (as in **RUP** — Rational Unified Process) with the simplified **PMI effort allocation** (10% inception/Initiating, 20% planning, 60% executing, 10% ending/Closing) and a common **data science process** like **ASK → GET → EXPLORE → MODEL → COMMUNICATE** (a streamlined, five-phase workflow often used in analytics and data science education/practice), you can map them conceptually by aligning focus areas, activities, and approximate effort distribution.\n",
    "\n",
    "This creates a **hybrid view** suitable for data science / ML projects in enterprise settings, where software engineering rigor (RUP/PMI) meets data-specific workflows. Data science projects are highly iterative, with heavy emphasis on data handling and experimentation, so effort is rarely linear—**data prep/exploration often consumes 50–70%** of total time in real projects.\n",
    "\n",
    "### Mapping Table\n",
    "\n",
    "| RUP Phase          | PMI Simplified (Effort %) | Data Science Phase (ASK-GET-EXPLORE-MODEL-COMMUNICATE) | Key Alignment & Typical Activities | Approx. Effort in DS Projects |\n",
    "|--------------------|---------------------------|----------------------------------------------------------|------------------------------------|-------------------------------|\n",
    "| **Inception**     | ~10% (Initiating)        | **ASK** (Define the question/problem)                   | Business understanding, problem framing, stakeholder alignment, high-level feasibility, success criteria (e.g., \"What business question are we solving? Is it predictive?\"). Outputs: project charter, initial hypothesis. | 5–15% (quick but critical to avoid wrong direction) |\n",
    "| **Elaboration**   | ~20% (Planning)          | **GET** + early **EXPLORE**                             | Data acquisition (GET: collect, access, integrate sources), initial data assessment, quality checks, high-level EDA, risk identification (e.g., data gaps, ethics), detailed planning (architecture, tools, baseline models). Outputs: data pipeline sketch, refined scope. | 15–30% (planning + initial data wrangling) |\n",
    "| **Construction**  | ~60% (Executing)         | **EXPLORE** + **MODEL**                                 | Deep exploratory data analysis (EXPLORE: visualizations, patterns, feature engineering), iterative modeling (MODEL: build, tune, validate ML/statistical models, experiment with algorithms), testing, integration. This is the \"heavy lifting\" core. Outputs: working models, performance metrics. | 50–70% (most time here—data cleaning + iteration dominate) |\n",
    "| **Transition**    | ~10% (Closing/Ending)    | **COMMUNICATE** (and deploy/handover)                   | Interpret results, create reports/dashboards/stories, stakeholder presentations, recommendations, deployment planning (if production), lessons learned, handover to ops/maintenance. Outputs: final insights, business recommendations, model documentation. | 10–20% (presentation + wrap-up; deployment may extend this) |\n",
    "\n",
    "### Key Insights for Relating Them\n",
    "- **RUP's iterative nature** fits data science well: You run multiple short cycles (iterations/sprints) especially in Construction (EXPLORE + MODEL), where you prototype, fail fast, refine features/models.\n",
    "- **PMI's 10-20-60-10 split** is a rough heuristic that works reasonably for data science if you treat **EXPLORE + MODEL as the 60% \"executing\" bulk**. In practice, many DS projects skew even more toward exploration/modeling (often 60–80% combined), with less upfront planning if data is uncertain.\n",
    "- **ASK** aligns perfectly with Inception/Initiating — skip or rush this, and the whole project fails (wrong problem solved).\n",
    "- **GET + EXPLORE** often blend into Elaboration + early Construction; data prep/exploration is notoriously time-intensive (frequently cited as 60–80% of effort in real DS workflows).\n",
    "- **COMMUNICATE** extends beyond pure closing — it includes storytelling, visualization, and influencing decisions, which is make-or-break in enterprise DS.\n",
    "- For **hybrid projects** (e.g., building a production ML system), use RUP/PMI for overall governance (milestones, risk logs, earned value) and the ASK-GET-EXPLORE-MODEL-COMMUNICATE inside each phase, especially in Construction.\n",
    "\n",
    "### Practical Advice\n",
    "- **Start with ASK/Inception** rigorously (define SMART questions, ROI hypotheses) to control scope.\n",
    "- **Time-box aggressively** in GET/EXPLORE to avoid endless tinkering.\n",
    "- Track actual effort per phase in your next project to refine these percentages for your context (e.g., via timesheets or tools like Jira, Git, GitHub, Trello).\n",
    "- If the project scales to production, add a \"Deploy & Maintain\" extension after COMMUNICATE (aligning with RUP Transition + PMI Closing + ongoing MLOps).\n",
    "\n",
    "This mapping helps bridge traditional software/PMI thinking with the more fluid, data-centric reality of DS projects. If you share your specific project type (e.g., predictive maintenance, customer analytics), I can tailor the alignment further!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba5fea-ddd5-4451-82f3-bf5cd70747f0",
   "metadata": {},
   "source": [
    "## Data Science Project 16-Week Breakdown¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f4063-863c-48c3-b703-75b095df3967",
   "metadata": {},
   "source": [
    "A realistic **16-week Data Science PoC** (approximately 4 months) is a solid, time-boxed duration for enterprise settings. It allows enough depth to deliver credible results (e.g., validated model with performance metrics, insights, and a demo) while avoiding scope creep.\n",
    "\n",
    "This breakdown uses the **ASK → GET → EXPLORE → MODEL → COMMUNICATE** workflow we discussed earlier, blended with RUP/PMI-inspired phasing:\n",
    "- Weeks 1–2 ≈ Inception/Initiating (~10–12%)\n",
    "- Weeks 3–5 ≈ Elaboration/Planning (~20%)\n",
    "- Weeks 6–13 ≈ Construction/Executing (~50–55%)\n",
    "- Weeks 14–16 ≈ Transition/Closing (~15%)\n",
    "\n",
    "Data science PoCs often front-load uncertainty (data issues) and back-load iteration/experimentation, so expect flexibility—especially in **EXPLORE** and **MODEL**, where surprises are common.\n",
    "\n",
    "### Suggested 16-Week Breakdown\n",
    "\n",
    "| Weeks | Phase (Workflow)              | Main Focus & Key Activities                                                                 | Deliverables / Milestones                          | % of Total Effort | Notes / Risks to Watch |\n",
    "|-------|-------------------------------|---------------------------------------------------------------------------------------------|----------------------------------------------------|-------------------|------------------------|\n",
    "| **1** | **ASK** (Inception / Initiating) | - Kickoff meetings, stakeholder alignment<br>- Define exact business problem & success criteria (e.g., \"improve forecast accuracy by X%\")<br>- Scope the PoC ruthlessly (one use case, limited data sources)<br>- Identify risks, resources, tools | - Project charter / PoC brief<br>- Defined KPIs & success thresholds<br>- High-level timeline & roles | ~6%              | Rush this → wrong problem solved. Involve business early. |\n",
    "| **2** | **ASK** + early **GET**      | - Refine questions/hypotheses<br>- Data source inventory & access requests<br>- Quick feasibility checks (sample data preview)<br>- Set up environment (cloud notebooks, repos) | - Data access plan<br>- Initial hypothesis document<br>- Environment ready | ~6%              | Data access delays are the #1 killer—start requests Day 1. |\n",
    "| **3–4** | **GET** (Elaboration / Planning) | - Acquire & ingest data (ETL pipelines, queries, exports)<br>- Basic data profiling & quality assessment<br>- Handle initial integration issues | - Raw data loaded in workable format<br>- Data quality report (missing values, outliers, schema) | ~12%             | Allocate buffer here; poor data quality can derail later phases. |\n",
    "| **5** | **GET** → **EXPLORE** transition | - Final data cleaning & basic feature prep<br>- Start light EDA (distributions, correlations)<br>- Refine scope based on data reality | - Cleaned dataset ready for deep analysis<br>- Initial EDA notebook | ~6%              | If data is unusable, pivot or kill PoC early (save time/money). |\n",
    "| **6–9** | **EXPLORE** (Construction / Executing – heavy) | - Deep exploratory data analysis<br>- Visualization & pattern discovery<br>- Feature engineering iterations<br>- Hypothesis testing & segmentation | - Comprehensive EDA report / dashboard<br>- Feature set & engineering pipeline<br>- Insights summary (patterns, drivers, issues) | ~25%             | Often the longest phase in reality—data prep + exploration eats 50–70% of DS time. Iterate fast. |\n",
    "| **10–13** | **MODEL** (Construction / Executing – peak) | - Baseline models (simple → advanced)<br>- Train / validate / tune (cross-validation, hyperparams)<br>- Error analysis & iteration<br>- Compare multiple approaches<br>- Select best model(s) | - Working model(s) with metrics (accuracy, precision, etc.)<br>- Model comparison table<br>- Validation report | ~25%             | Focus on quick wins first (e.g., logistic regression baseline), then complex (XGBoost, NN). Avoid over-engineering. |\n",
    "| **14–15** | **COMMUNICATE** (Transition / Closing) | - Interpret results vs. business goals<br>- Build story: insights, recommendations, limitations<br>- Create demo / dashboard / slides<br>- Prepare Q&A for stakeholders | - Executive summary & presentation deck<br>- Demo (notebook, Streamlit/Shiny app, or simple UI)<br>- Final report with metrics & next steps | ~12%             | Storytelling is key—business cares about impact, not AUC alone. |\n",
    "| **16** | **COMMUNICATE** + Wrap-up     | - Stakeholder presentation & feedback session<br>- Document everything (code, decisions, learnings)<br>- Handover artifacts<br>- Retrospective & recommendations for full project | - PoC closure document<br>- Repo / artifacts archived<br>- Lessons learned | ~6%              | End with clear \"go/no-go\" recommendation + scaled plan. |\n",
    "\n",
    "### Quick Summary of Effort Allocation\n",
    "- Weeks 1–5 (ASK + GET + early EXPLORE): ~30% (planning & data foundation)\n",
    "- Weeks 6–13 (core EXPLORE + MODEL): ~50% (the \"make or break\" execution bulk)\n",
    "- Weeks 14–16 (COMMUNICATE + close): ~20% (value demonstration & handover)\n",
    "\n",
    "### Practical Tips for a 16-Week PoC\n",
    "- Use agile sprints (2-week cycles) inside the phases for reviews & adjustments.\n",
    "- Build in 1–2 buffer weeks (e.g., absorb into weeks 8–9 or 12–13) for data surprises or model struggles.\n",
    "- Weekly check-ins with stakeholders keep alignment and catch issues early.\n",
    "- Track progress against KPIs weekly to avoid last-minute rushes.\n",
    "- Document as you go—notebooks + a central Confluence/Jira/Notion page.\n",
    "\n",
    "This is a balanced, realistic template for a medium-complexity enterprise PoC (e.g., predictive churn, demand forecast, anomaly detection). Adjust based on your data readiness (if data is already clean, shift more time to MODEL) or complexity (e.g., GenAI or computer vision needs extra weeks in MODEL). If you tell me the specific use case (industry, goal, data volume), I can fine-tune it further!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a10e4c-ec1d-4d5a-9d56-521c3cd764df",
   "metadata": {},
   "source": [
    "## Data Scientist Background\n",
    "\n",
    "The **average educational background** for data scientists, based on recent analyses of job postings (primarily from 2024–2025 data sourced from platforms like Glassdoor, Indeed, and industry reports), shows a strong preference for **advanced degrees** in quantitative fields. While requirements vary by role level (entry-level vs. senior), company, and region, the field remains highly educated overall.\n",
    "\n",
    "### Key Trends from Job Postings (2025 Data)\n",
    "Recent studies (e.g., analyzing 1,000+ postings on Glassdoor and similar sources) indicate:\n",
    "- **Graduate degrees** (Master's or PhD) are the most common expectation or preference.\n",
    "- Many postings (around 17–26% in some samples) do not explicitly require a specific degree level, emphasizing skills/experience instead.\n",
    "- There's a noticeable shift toward higher requirements in maturing markets: e.g., PhD mentions rose significantly from ~24% in 2024 to ~35% in 2025 in one major analysis.\n",
    "\n",
    "### Breakdown of Education Levels in Job Postings (Approximate Percentages, 2025)\n",
    "| Education Level       | % of Job Postings Requiring/Preferring It | Notes |\n",
    "|-----------------------|-------------------------------------------|-------|\n",
    "| Bachelor's only      | 16–20%                                   | Often sufficient for entry-level or less complex roles; common in quantitative fields. |\n",
    "| Master's             | 29–31%                                   | Most frequently mentioned as the \"ideal\" or required level; dominant for mid-level positions. |\n",
    "| PhD                  | 24–35%                                   | Increasingly common (up ~10% YoY in some data); typical for research-heavy, senior, or AI-focused roles. |\n",
    "| No specific degree mentioned | 18–27%                               | Focus shifts to proven skills, portfolios, certifications, or bootcamps/bootcamp equivalents. |\n",
    "\n",
    "- In 2025, ~70% of postings explicitly require or prefer a **data science-specific degree** (up sharply from ~47% in 2024), reflecting industry maturation.\n",
    "- For context, older surveys (pre-2024) sometimes showed ~88% with Master's+ and ~46% with PhDs among practicing data scientists, but job postings now reflect more flexibility due to talent shortages and emphasis on practical abilities.\n",
    "\n",
    "### Most Common Fields of Study (Undergraduate + Postgraduate)\n",
    "Job postings and hiring trends consistently highlight **quantitative/STEM backgrounds** as the foundation:\n",
    "- **Computer Science** — One of the top-mentioned (often 18–25%+ of postings).\n",
    "- **Statistics / Mathematics** — Extremely common (frequently 17–22%).\n",
    "- **Engineering** (various, e.g., electrical, industrial) — Around 20–23%.\n",
    "- **Data Science** (specific major) — Rising fast, especially at Master's level.\n",
    "- Others: Physics, Economics, Operations Research, or related quantitative disciplines.\n",
    "\n",
    "These provide the core skills in programming (Python/R), statistics, linear algebra, and machine learning fundamentals.\n",
    "\n",
    "### Summary and Advice\n",
    "- **Average profile**: Most competitive candidates hold at least a **Master's** (often the sweet spot for the majority of roles), frequently in **Computer Science**, **Statistics**, **Mathematics**, or **Data Science** itself. A PhD is advantageous (and sometimes expected) for advanced/research-oriented positions, but not universal.\n",
    "- **Flexibility growing**: ~20–25% of postings accept strong practical experience, portfolios, bootcamps, or certifications (e.g., Google/IBM Data Science certs) in lieu of advanced degrees—especially for mid-level or applied roles.\n",
    "- In Brazil/LATAM (relevant given your location), trends align globally but with more emphasis on local Master's programs or international certifications due to competitive talent pools and slightly lower barriers for skills-based hiring.\n",
    "\n",
    "If you're evaluating your own background or planning next steps (e.g., pursuing a Master's or building a portfolio), share more details for tailored advice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499e6a3-94ff-4478-814a-90b31c4e42f5",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Here are the main references and sources I drew from (or that align closely with) the data on **data scientist educational backgrounds**, degree levels, and common fields of study based on 2025 job postings and industry analyses:\n",
    "\n",
    "### Primary Sources with 2025-Specific Data\n",
    "- **365 Data Science – Data Scientist Job Outlook 2025: Trends, Salaries, and Skills**  \n",
    "  https://365datascience.com/career-advice/career-guides/data-scientist-job-outlook-2025  \n",
    "  (Key stats: Job postings requiring a data science degree rose from 47% in 2024 to 70% in 2025; breakdown of education levels: Bachelor's ~16.2%, Master's ~31.4%, PhD ~34.7%, Not mentioned ~17.7%.)\n",
    "\n",
    "- **Burtch Works – 2025 AI & Data Science Degrees Outlook**  \n",
    "  https://www.burtchworks.com/market-researchers-salary-report-2025/ai-and-data-science-2025compensationreport-education  \n",
    "  (Highlights: 91% of AI professionals hold a graduate degree in 2025, with Master's overtaking PhD as the dominant credential at 64%.)\n",
    "\n",
    "- **U.S. Bureau of Labor Statistics (BLS) – Data Scientists Occupational Outlook Handbook** (updated August 2025)  \n",
    "  https://www.bls.gov/ooh/math/data-scientists.htm  \n",
    "  (Typical entry-level: Bachelor's in math, statistics, computer science, or related; many employers prefer/require Master's or PhD; common fields listed include mathematics, statistics, computer science, business, engineering.)\n",
    "\n",
    "- **Zippia / Coursera / Dataquest** (cross-referenced demographics, often cited in 2025 reports)  \n",
    "  https://www.zippia.com/data-scientist-jobs/demographics/ (via Coursera: ~51% Bachelor's, 34% Master's, 13% PhD among practicing data scientists; similar patterns in job requirements.)\n",
    "\n",
    "### Additional Supporting Sources\n",
    "- **Interview Query – State of University Report / Master's in Data Science Analysis**  \n",
    "  https://www.interviewquery.com/p/state-of-university-report  \n",
    "  (~70% of data scientists hold a Master's; common Master's pursuits: 48% Data Science, 27% Business Analytics, 26% Data Analytics.)\n",
    "\n",
    "- **Northeastern University / Harvard Extension School / Various Career Guides** (2025 updates)  \n",
    "  Emphasize quantitative fields: Computer Science, Statistics/Mathematics, Engineering as top feeders; Master's often preferred for mid/senior roles.\n",
    "\n",
    "These reflect aggregated trends from job platforms (e.g., Glassdoor, Indeed, LinkedIn analyses referenced indirectly in reports), BLS projections, and specialized 2025 market research. Percentages vary slightly by source due to sample differences (e.g., US-focused vs. global, entry-level vs. all levels), but the consensus is: Master's is the most common \"sweet spot,\" PhD is rising for advanced/AI roles, and Bachelor's suffices for some entry positions with strong skills.\n",
    "\n",
    "If you'd like me to dive deeper into any specific source, pull quotes, or check a particular aspect (e.g., Brazil/LATAM trends), just say the word!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f066194d-f71b-4fb7-8e91-122951e1dc9a",
   "metadata": {},
   "source": [
    "## More References\n",
    "\n",
    "- https://br.indeed.com/\n",
    "- https://www.glassdoor.com/\n",
    "- https://survey.stackoverflow.co/2025/\n",
    "- https://www.geeksforgeeks.org/machine-learning/data-science-process/\n",
    "- https://pmisp.org.br/\n",
    "- https://pt.wikipedia.org/wiki/IBM_Rational_Unified_Process\n",
    "- https://en.wikipedia.org/wiki/Enterprise_unified_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280bb67-dafb-492b-b9d2-3550d6fba49c",
   "metadata": {},
   "source": [
    "## Extra...\n",
    "\n",
    "<div style=\"width:600px\">\n",
    "\n",
    "![](img/data-science-process.jpg)\n",
    "\n",
    "</div>\n",
    "\n",
    "https://www.otechtalks.tv/67-what-is-data-science-learning-the-basics/\n",
    "\n",
    "Wolfram Data Science Process\n",
    "\n",
    "<div style=\"width:600px\">\n",
    "\n",
    "![](img/dat103-course.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "https://www.wolfram.com/wolfram-u/courses/catalog/?topic=data-science"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
